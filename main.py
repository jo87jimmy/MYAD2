import torch  # å¼•å…¥ PyTorch
from dataset import get_data_transforms  # å¾ dataset.py è¼‰å…¥è³‡æ–™è½‰æ›å‡½å¼
from torchvision.datasets import ImageFolder  # ç”¨æ–¼å½±åƒè³‡æ–™å¤¾çš„è³‡æ–™é›†
import numpy as np  # æ•¸å€¼è¨ˆç®—å¥—ä»¶
import random  # äº‚æ•¸æ§åˆ¶
import os  # æª”æ¡ˆç³»çµ±æ“ä½œ
from torch.utils.data import DataLoader  # PyTorch çš„è³‡æ–™è¼‰å…¥å™¨
from dataset import MVTecDataset  # MVTec è³‡æ–™é›†é¡åˆ¥
import torch.backends.cudnn as cudnn  # CUDA cuDNN åŠ é€Ÿ
import argparse  # å‘½ä»¤åˆ—åƒæ•¸è™•ç†
from test import evaluation, visualization, test  # æ¸¬è©¦ã€è©•ä¼°èˆ‡å¯è¦–åŒ–å‡½å¼
from torch.nn import functional as F  # å¼•å…¥ PyTorch çš„å‡½å¼ä»‹é¢
from model_unet import ReconstructiveSubNetwork, DiscriminativeSubNetwork  # å‡è¨­ä½ çš„ DRAEM å®šç¾©åœ¨ models/draem.py


def setup_seed(seed):
    # è¨­å®šéš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿å¯¦é©—å¯é‡ç¾
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True  # ä¿è­‰çµæœå¯é‡ç¾
    torch.backends.cudnn.benchmark = False  # é—œé–‰è‡ªå‹•æœ€ä½³åŒ–æœå°‹


# è’¸é¤¾æå¤±å‡½æ•¸
def distillation_loss(teacher_features, student_features):
    cos_loss = torch.nn.CosineSimilarity()
    if not isinstance(teacher_features, (list, tuple)):
        teacher_features, student_features = [teacher_features
                                              ], [student_features]

    loss = 0
    for i in range(len(teacher_features)):
        loss += torch.mean(1 - cos_loss(
            teacher_features[i].view(teacher_features[i].shape[0], -1),
            student_features[i].view(student_features[i].shape[0], -1)))
    return loss


def train(_arch_, _class_, epochs, save_pth_path):
    # è¨“ç·´æµç¨‹
    print(f"ğŸ”§ é¡åˆ¥: {_class_} | Epochs: {epochs}")
    learning_rate = 0.005  # å­¸ç¿’ç‡
    # batch_size = 16  # æ‰¹æ¬¡å¤§å°
    batch_size = 8  # æ‰¹æ¬¡å¤§å°
    image_size = 256  # è¼¸å…¥å½±åƒå¤§å°

    device = 'cuda' if torch.cuda.is_available() else 'cpu'  # é¸æ“‡è£ç½®
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è£ç½®: {device}")

    # è³‡æ–™è½‰æ›
    data_transform, gt_transform = get_data_transforms(image_size, image_size)
    train_path = f'./mvtec/{_class_}/train'  # è¨“ç·´è³‡æ–™è·¯å¾‘
    test_path = f'./mvtec/{_class_}'  # æ¸¬è©¦è³‡æ–™è·¯å¾‘

    # è¼‰å…¥è¨“ç·´èˆ‡æ¸¬è©¦è³‡æ–™
    train_data = ImageFolder(root=train_path, transform=data_transform)
    test_data = MVTecDataset(root=test_path,
                             transform=data_transform,
                             gt_transform=gt_transform,
                             phase="test")

    # å»ºç«‹ DataLoader
    train_dataloader = torch.utils.data.DataLoader(train_data,
                                                   batch_size=batch_size,
                                                   shuffle=True)
    test_dataloader = torch.utils.data.DataLoader(test_data,
                                                  batch_size=1,
                                                  shuffle=False)

    # æ•™å¸«æ¨¡å‹ï¼ˆé è¨“ç·´ DRAEMï¼Œå‡çµï¼‰
    teacher_encoder = ReconstructiveSubNetwork(in_channels=3, out_channels=3)
    teacher_decoder = DiscriminativeSubNetwork(in_channels=6, out_channels=2)
    # === Step 2: è¼‰å…¥ checkpoint ===
    encoder_ckpt = torch.load(
        "DRAEM_seg_large_ae_large_0.0001_800_bs8_bottle_.pckl",
        map_location=device,
        weights_only=True)
    decoder_ckpt = torch.load(
        "DRAEM_seg_large_ae_large_0.0001_800_bs8_bottle__seg.pckl",
        map_location=device,
        weights_only=True)
    teacher_encoder.load_state_dict(encoder_ckpt)
    teacher_decoder.load_state_dict(decoder_ckpt)
    # é‡è¦ï¼šè¼‰å…¥æ¬Šé‡å¾Œå†ç§»åˆ°è¨­å‚™
    teacher_encoder = teacher_encoder.to(device)
    teacher_decoder = teacher_decoder.to(device)
    teacher_encoder.eval()
    teacher_decoder.eval()

    # å­¸ç”Ÿæ¨¡å‹ï¼ˆéœ€è¦è¨“ç·´ï¼‰
    student_encoder = ReconstructiveSubNetwork(in_channels=3, out_channels=3)
    student_decoder = DiscriminativeSubNetwork(in_channels=6, out_channels=2)
    student_encoder = student_encoder.to(device)
    student_decoder = student_decoder.to(device)

    # å»ºç«‹å„ªåŒ–å™¨ï¼Œè¨“ç·´å­¸ç”Ÿæ¨¡å‹
    optimizer = torch.optim.Adam(list(student_encoder.parameters()) +
                                 list(student_decoder.parameters()),
                                 lr=learning_rate,
                                 betas=(0.5, 0.999))

    # å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾
    save_pth_dir = save_pth_path if save_pth_path else 'pths/best'
    os.makedirs(save_pth_dir, exist_ok=True)

    # è¨­å®šæœ€ä½³æ¬Šé‡æª”æ¡ˆå­˜æ”¾è·¯å¾‘
    best_ckp_path = os.path.join(save_pth_dir, f'best_{_arch_}_{_class_}.pth')

    # åˆå§‹åŒ–æœ€ä½³åˆ†æ•¸
    best_score = -1

    # è¨“ç·´è¿´åœˆ
    for epoch in range(epochs):
        student_encoder.train()
        student_decoder.train()
        loss_list = []

        for img, label in train_dataloader:
            img = img.to(device)

            # æ•™å¸«æ¨¡å‹æ¨ç†
            with torch.no_grad():
                teacher_recon = teacher_encoder(img)
                teacher_input = torch.cat([img, teacher_recon], dim=1)
                teacher_seg = teacher_decoder(teacher_input)

            # å­¸ç”Ÿæ¨¡å‹æ¨ç†
            student_recon = student_encoder(img)
            student_input = torch.cat([img, student_recon], dim=1)
            student_seg = student_decoder(student_input)

            # è’¸é¤¾æå¤±ï¼šæ¯”è¼ƒç›¸åŒèªç¾©çš„è¼¸å‡º
            recon_loss = distillation_loss(teacher_recon, student_recon)
            seg_loss = distillation_loss(teacher_seg, student_seg)

            total_loss = recon_loss + seg_loss

            optimizer.zero_grad()
            total_loss.backward()  # ä¿®æ­£ï¼šä½¿ç”¨ total_loss
            optimizer.step()
            loss_list.append(total_loss.item())

        print(
            f"ğŸ“˜ Epoch [{epoch + 1}/{epochs}] | Loss: {np.mean(loss_list):.4f}")

        # æ¯å€‹ epoch éƒ½é€²è¡Œä¸€æ¬¡è©•ä¼°ï¼ˆä½¿ç”¨å­¸ç”Ÿæ¨¡å‹ï¼‰
        auroc_px, auroc_sp, aupro_px = evaluation(student_encoder,
                                                  student_decoder,
                                                  test_dataloader, device)
        print(f"ğŸ” è©•ä¼° | Pixel AUROC: {auroc_px:.3f}")

        # å¦‚æœè¡¨ç¾æ›´å¥½å‰‡å„²å­˜å­¸ç”Ÿæ¨¡å‹
        if auroc_px > best_score:
            best_score = auroc_px
            torch.save(
                {
                    'encoder': student_encoder.state_dict(),
                    'decoder': student_decoder.state_dict()
                }, best_ckp_path)
            print(f"ğŸ’¾ æ›´æ–°æœ€ä½³æ¨¡å‹ â†’ {best_ckp_path}")

    # è¨“ç·´çµæŸå›å‚³æœ€ä½³çµæœ
    return best_ckp_path, best_score, auroc_sp, aupro_px, student_encoder, student_decoder


if __name__ == '__main__':
    import argparse
    import pandas as pd
    import os
    import torch

    # è§£æå‘½ä»¤åˆ—åƒæ•¸
    parser = argparse.ArgumentParser()
    parser.add_argument('--category', default='bottle', type=str)  # è¨“ç·´é¡åˆ¥
    parser.add_argument('--epochs', default=25, type=int)  # è¨“ç·´å›åˆæ•¸
    parser.add_argument('--arch', default='wres50', type=str)  # æ¨¡å‹æ¶æ§‹
    args = parser.parse_args()

    setup_seed(111)  # å›ºå®šéš¨æ©Ÿç¨®å­
    save_visual_path = f"results/{args.arch}_{args.category}"
    save_pth_path = f"pths/best_{args.arch}_{args.category}"
    # é–‹å§‹è¨“ç·´ï¼Œä¸¦æ¥æ”¶æœ€ä½³æ¨¡å‹è·¯å¾‘èˆ‡çµæœ
    best_ckp, auroc_px, auroc_sp, aupro_px, bn, decoder = train(
        args.arch, args.category, args.epochs, save_pth_path)

    print(f"æœ€ä½³æ¨¡å‹: {best_ckp}")

    # å­˜è¨“ç·´æŒ‡æ¨™åˆ° CSV
    df_metrics = pd.DataFrame([{
        'Category': args.category,
        'Pixel_AUROC': auroc_px,
        'Sample_AUROC': auroc_sp,
        'Pixel_AUPRO': aupro_px,
        'Epochs': args.epochs
    }])
    metrics_name = f"metrics_{args.arch}_{args.category}.csv"
    df_metrics.to_csv(metrics_name,
                      mode='a',
                      header=not os.path.exists(metrics_name),
                      index=False)

    # ğŸ”¥ è¨“ç·´çµæŸå¾Œè‡ªå‹•ç”¢ç”Ÿå¯è¦–åŒ–çµæœ
    visualization(args.arch,
                  args.category,
                  ckp_path=best_ckp,
                  save_path=save_visual_path)
